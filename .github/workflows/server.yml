name: Server CI

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'server/**'
      - '.github/workflows/server.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'server/**'
      - '.github/workflows/server.yml'
  workflow_dispatch:

# Cancel in-progress runs for the same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  importer-tests:
    name: Importer Tests
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-asyncio pytest-cov aiohttp beautifulsoup4 pluggy

    - name: Run Importer Tests with Coverage
      run: |
        cd server/importers
        # Note: Coverage threshold is 45% as many source plugins are stubs/WIP
        # TODO: Increase threshold as more tests are added
        python -m pytest tests/ -v --tb=short --cov=. --cov-report=xml --cov-report=term-missing --cov-fail-under=45

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      if: always()
      with:
        directory: server/importers
        flags: importer
        fail_ci_if_error: false
      continue-on-error: true

    - name: Summary
      if: always()
      run: |
        echo "## Importer Test Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
        echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
        echo "| Status | ${{ job.status == 'success' && 'Passed' || 'Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Coverage Threshold | 45% |" >> $GITHUB_STEP_SUMMARY

  management-tests:
    name: Management Server Tests
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-asyncio pytest-aiohttp pytest-cov aiohttp bcrypt PyJWT aiofiles

    - name: Run Management Server Tests with Coverage
      run: |
        cd server/management
        python -m pytest tests/ -v --tb=short --cov=. --cov-report=xml --cov-report=term-missing --cov-fail-under=70

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      if: always()
      with:
        directory: server/management
        flags: management
        fail_ci_if_error: false
      continue-on-error: true

    - name: Summary
      if: always()
      run: |
        echo "## Management Server Test Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
        echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
        echo "| Status | ${{ job.status == 'success' && 'Passed' || 'Failed' }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Coverage Threshold | 70% |" >> $GITHUB_STEP_SUMMARY

  latency-harness-tests:
    name: Latency Harness Tests
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-asyncio aiohttp

    - name: Run Quick Validation
      run: |
        cd server
        python -m latency_harness.cli --suite quick_validation --mock --ci --timeout 120 --output text
      continue-on-error: true

    - name: Summary
      if: always()
      run: |
        echo "## Latency Harness Test Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
        echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
        echo "| Status | ${{ job.status == 'success' && 'Passed' || 'Check logs' }} |" >> $GITHUB_STEP_SUMMARY

  python-lint:
    name: Python Lint
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install linting tools
      run: |
        python -m pip install --upgrade pip
        pip install ruff

    - name: Run Ruff Linter
      run: |
        ruff check server/ --output-format=github || true
      continue-on-error: true

    - name: Summary
      if: always()
      run: |
        echo "## Python Lint Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "Linting completed. Check logs for details." >> $GITHUB_STEP_SUMMARY

  summary:
    name: Server CI Summary
    runs-on: ubuntu-latest
    needs: [importer-tests, management-tests, latency-harness-tests, python-lint]
    if: always()

    steps:
    - name: Generate Summary
      env:
        IMPORTER_RESULT: ${{ needs.importer-tests.result }}
        MANAGEMENT_RESULT: ${{ needs.management-tests.result }}
        LATENCY_RESULT: ${{ needs.latency-harness-tests.result }}
        LINT_RESULT: ${{ needs.python-lint.result }}
      run: |
        echo "## Server CI Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| Importer Tests | ${IMPORTER_RESULT} |" >> $GITHUB_STEP_SUMMARY
        echo "| Management Tests | ${MANAGEMENT_RESULT} |" >> $GITHUB_STEP_SUMMARY
        echo "| Latency Harness | ${LATENCY_RESULT} |" >> $GITHUB_STEP_SUMMARY
        echo "| Python Lint | ${LINT_RESULT} |" >> $GITHUB_STEP_SUMMARY
