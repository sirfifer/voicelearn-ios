{
  "version": "1.0",
  "description": "Cross-platform validation test vectors for Knowledge Bowl answer validation",
  "last_updated": "2026-01-19",
  "test_cases": [
    {
      "id": "phonetic_001",
      "category": "phonetic",
      "user_answer": "Stephen",
      "correct_answer": "Steven",
      "answer_type": "person",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "phonetic",
      "expected_metaphone_primary": "STFN"
    },
    {
      "id": "phonetic_002",
      "category": "phonetic",
      "user_answer": "Catherine",
      "correct_answer": "Kathryn",
      "answer_type": "person",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "phonetic"
    },
    {
      "id": "phonetic_003",
      "category": "phonetic",
      "user_answer": "Philadelphia",
      "correct_answer": "Filadelfia",
      "answer_type": "place",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "phonetic"
    },
    {
      "id": "ngram_001",
      "category": "ngram",
      "user_answer": "Mississippi",
      "correct_answer": "Missisipi",
      "answer_type": "place",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "ngram",
      "expected_score_min": 0.80
    },
    {
      "id": "ngram_002",
      "category": "ngram",
      "user_answer": "Connecticut",
      "correct_answer": "Conneticut",
      "answer_type": "place",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "ngram",
      "expected_score_min": 0.80
    },
    {
      "id": "ngram_003",
      "category": "ngram",
      "user_answer": "Photosynthesis",
      "correct_answer": "Fotosynthesis",
      "answer_type": "scientific",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "ngram",
      "expected_score_min": 0.80
    },
    {
      "id": "token_001",
      "category": "token",
      "user_answer": "United States of America",
      "correct_answer": "United States",
      "answer_type": "place",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "token",
      "expected_score_min": 0.60
    },
    {
      "id": "token_002",
      "category": "token",
      "user_answer": "States United",
      "correct_answer": "United States",
      "answer_type": "place",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "token",
      "expected_score_min": 0.95
    },
    {
      "id": "token_003",
      "category": "token",
      "user_answer": "The Great Gatsby",
      "correct_answer": "Great Gatsby",
      "answer_type": "title",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "token",
      "expected_score_min": 0.95
    },
    {
      "id": "synonym_001",
      "category": "synonym",
      "user_answer": "USA",
      "correct_answer": "United States",
      "answer_type": "place",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "synonym"
    },
    {
      "id": "synonym_002",
      "category": "synonym",
      "user_answer": "CO2",
      "correct_answer": "Carbon Dioxide",
      "answer_type": "scientific",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "synonym"
    },
    {
      "id": "synonym_003",
      "category": "synonym",
      "user_answer": "H2O",
      "correct_answer": "Water",
      "answer_type": "scientific",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "synonym"
    },
    {
      "id": "synonym_004",
      "category": "synonym",
      "user_answer": "WWI",
      "correct_answer": "World War I",
      "answer_type": "text",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "synonym"
    },
    {
      "id": "synonym_005",
      "category": "synonym",
      "user_answer": "DNA",
      "correct_answer": "Deoxyribonucleic Acid",
      "answer_type": "scientific",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "synonym"
    },
    {
      "id": "linguistic_001",
      "category": "linguistic",
      "user_answer": "running",
      "correct_answer": "run",
      "answer_type": "text",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "linguistic"
    },
    {
      "id": "linguistic_002",
      "category": "linguistic",
      "user_answer": "cats",
      "correct_answer": "cat",
      "answer_type": "text",
      "expected_match": true,
      "expected_tier": 1,
      "expected_algorithm": "linguistic"
    },
    {
      "id": "embeddings_001",
      "category": "embeddings",
      "user_answer": "water",
      "correct_answer": "H2O",
      "answer_type": "scientific",
      "expected_match": true,
      "expected_tier": 2,
      "expected_algorithm": "embeddings",
      "expected_similarity_min": 0.85
    },
    {
      "id": "embeddings_002",
      "category": "embeddings",
      "user_answer": "table salt",
      "correct_answer": "NaCl",
      "answer_type": "scientific",
      "expected_match": true,
      "expected_tier": 2,
      "expected_algorithm": "embeddings",
      "expected_similarity_min": 0.85
    },
    {
      "id": "llm_001",
      "category": "llm",
      "user_answer": "the powerhouse of the cell",
      "correct_answer": "mitochondria",
      "answer_type": "scientific",
      "expected_match": true,
      "expected_tier": 3,
      "expected_algorithm": "llm"
    },
    {
      "id": "llm_002",
      "category": "llm",
      "user_answer": "the author of Romeo and Juliet",
      "correct_answer": "William Shakespeare",
      "answer_type": "person",
      "expected_match": true,
      "expected_tier": 3,
      "expected_algorithm": "llm"
    },
    {
      "id": "non_match_001",
      "category": "non_match",
      "user_answer": "Apple",
      "correct_answer": "Zebra",
      "answer_type": "text",
      "expected_match": false,
      "expected_tier": 0,
      "expected_algorithm": "none"
    },
    {
      "id": "non_match_002",
      "category": "non_match",
      "user_answer": "Cat",
      "correct_answer": "Dog",
      "answer_type": "text",
      "expected_match": false,
      "expected_tier": 0,
      "expected_algorithm": "none"
    }
  ],
  "statistics": {
    "total_cases": 22,
    "tier_1_cases": 16,
    "tier_2_cases": 2,
    "tier_3_cases": 2,
    "non_match_cases": 2
  },
  "notes": [
    "This is a sample subset of test vectors",
    "Full test suite should contain 1000+ test cases",
    "Test vectors ensure cross-platform parity between iOS and Android",
    "Expected scores have ±5% tolerance for algorithm variations",
    "Expected similarity scores have ±2% tolerance for model variations"
  ]
}
