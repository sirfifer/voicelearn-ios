# Transcript-Driven Tutoring: Feasibility Analysis

**Core Question:** If we have a high-quality pre-generated transcript, how much of the tutoring experience can run on cheaper/on-device models before needing frontier AI?

---

## The Insight

A tutoring session has fundamentally different interaction types:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INTERACTION SPECTRUM                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  TRANSCRIPT-BOUND â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º GENERATIVE          â”‚
â”‚                                                                     â”‚
â”‚  â€¢ Read prepared content    â”‚    â”‚    â”‚    â€¢ Answer novel questionsâ”‚
â”‚  â€¢ Pace/pause naturally     â”‚    â”‚    â”‚    â€¢ Generate examples     â”‚
â”‚  â€¢ Simple acknowledgments   â”‚    â”‚    â”‚    â€¢ Explain differently   â”‚
â”‚  â€¢ "Let me repeat that"     â”‚    â”‚    â”‚    â€¢ Go on tangents        â”‚
â”‚  â€¢ "Moving on to..."        â”‚    â”‚    â”‚    â€¢ Check understanding   â”‚
â”‚  â€¢ Basic navigation         â”‚    â”‚    â”‚    â€¢ Adapt to confusion    â”‚
â”‚                             â”‚    â”‚    â”‚                            â”‚
â”‚  LOW AI CAPABILITY â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â–º HIGH AI CAPABILITY  â”‚
â”‚  (TTS + simple classifier)  â”‚    â”‚    â”‚    (Frontier LLM needed)  â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Breakdown of Tutoring Interactions

### Category A: No LLM Needed (Just TTS + Logic)

| Interaction | What Happens | AI Requirement |
|-------------|--------------|----------------|
| Lecture delivery | Read transcript with natural pacing | TTS only |
| Pause for emphasis | Detect punctuation, insert pauses | None (rules) |
| Section transitions | "Now let's talk about..." | TTS only |
| Time-based pacing | Slow down for complex parts | None (metadata) |

**Cost:** ~$0.015/1000 characters (TTS only)

### Category B: Tiny Model Sufficient (On-Device or GPT-4o-mini)

| Interaction | What Happens | AI Requirement |
|-------------|--------------|----------------|
| Simple acknowledgment | User says "okay" â†’ Continue | Intent classifier |
| Repeat request | "Can you say that again?" | Intent + replay |
| Pace adjustment | "Slow down" / "Speed up" | Intent + TTS rate |
| Basic confirmation | "Does that make sense?" (scripted) | Intent to detect response |
| Navigation | "Skip ahead" / "Go back" | Intent classifier |
| Filler responses | "Mmhmm", "Right", "I see" | On-device 1B |
| Echo back | "So you're saying..." (templated) | Simple slot-filling |

**Cost:** $0 (on-device) or ~$0.0001-0.001 (GPT-4o-mini)

### Category C: Medium Model Sufficient (Self-hosted 8B-70B)

| Interaction | What Happens | AI Requirement |
|-------------|--------------|----------------|
| Rephrase request | "Can you explain that differently?" | Needs comprehension |
| Simple example request | "Can you give an example?" | If examples in transcript: retrieve. If not: generate simple one |
| Clarification of specific term | "What does X mean?" | Can often be in transcript glossary, or simple definition |
| Summary request | "Can you summarize what we covered?" | Extractive summary of transcript sections covered |
| Connection question | "How does this relate to Y?" | If Y is in transcript: retrieve. If not: medium reasoning |

**Cost:** $0 (self-hosted) or ~$0.001-0.005 (GPT-4o-mini)

### Category D: Frontier Model Required (GPT-4o / Claude 3.5)

| Interaction | What Happens | AI Requirement |
|-------------|--------------|----------------|
| Novel question | "But what if X?" (not in transcript) | Real reasoning |
| Deep example | "Can you give a real-world example of..." | Creative generation |
| Tangent exploration | "That reminds me of Y, can we talk about that?" | Context + knowledge |
| Misconception detection | User says something subtly wrong | Deep comprehension |
| Socratic probing | Asking questions to check understanding | Pedagogical reasoning |
| Adaptive explanation | User still confused after rephrase | Needs to try new approach |
| Cross-topic synthesis | "How does this connect to what we learned last week?" | Long-term context |

**Cost:** ~$0.01-0.05 per interaction

---

## Estimated Session Breakdown

For a typical 60-minute tutoring session on a prepared topic:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TYPICAL SESSION INTERACTION MIX                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Category A (TTS + Logic):           ~40-50% of time               â”‚
â”‚  â”œâ”€â”€ Lecture delivery                 35%                          â”‚
â”‚  â”œâ”€â”€ Pauses, transitions              10%                          â”‚
â”‚  â””â”€â”€ Scripted checkpoints              5%                          â”‚
â”‚                                                                     â”‚
â”‚  Category B (Tiny Model):            ~25-35% of interactions       â”‚
â”‚  â”œâ”€â”€ Acknowledgments                  15%                          â”‚
â”‚  â”œâ”€â”€ Navigation requests               5%                          â”‚
â”‚  â”œâ”€â”€ Repeat/pace requests              5%                          â”‚
â”‚  â””â”€â”€ Simple confirmations             10%                          â”‚
â”‚                                                                     â”‚
â”‚  Category C (Medium Model):          ~15-20% of interactions       â”‚
â”‚  â”œâ”€â”€ Rephrase requests                 5%                          â”‚
â”‚  â”œâ”€â”€ Simple examples                   5%                          â”‚
â”‚  â””â”€â”€ Term clarifications               5%                          â”‚
â”‚                                                                     â”‚
â”‚  Category D (Frontier Model):        ~10-15% of interactions       â”‚
â”‚  â”œâ”€â”€ Novel questions                   5%                          â”‚
â”‚  â”œâ”€â”€ Deep examples                     3%                          â”‚
â”‚  â”œâ”€â”€ Understanding checks              5%                          â”‚
â”‚  â””â”€â”€ Tangents                          2%                          â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cost Comparison

| Strategy | Category A | Category B | Category C | Category D | Total |
|----------|------------|------------|------------|------------|-------|
| **All GPT-4o** | $0.02 | $0.50 | $0.30 | $0.30 | **$1.12** |
| **Transcript-Tiered** | $0.02 | $0 | $0 | $0.30 | **$0.32** |
| **Savings** | â€” | â€” | â€” | â€” | **72%** |

*Assumes: 50K chars spoken, 50 user interactions, self-hosted for C, on-device for B*

---

## How It Would Work

### Transcript Format (Pre-generated)

```json
{
  "topic": "Quantum Entanglement",
  "estimatedDuration": 45,
  "sections": [
    {
      "id": "intro",
      "type": "lecture",
      "content": "Let's explore one of the most fascinating phenomena in quantum physics: entanglement. Einstein famously called it 'spooky action at a distance'...",
      "speakingNotes": {
        "pace": "slow",
        "emphasis": ["spooky action at a distance"],
        "pauseAfter": true
      },
      "checkpoint": {
        "type": "simple_confirmation",
        "prompt": "Have you heard of quantum entanglement before?",
        "expectedResponses": ["yes", "no", "a little"],
        "transitions": {
          "yes": "Great, let's build on that foundation.",
          "no": "No problem, we'll start from the basics.",
          "a_little": "Perfect, let's clarify any fuzzy parts."
        }
      },
      "glossary": {
        "entanglement": "A quantum phenomenon where particles become correlated...",
        "superposition": "The ability of a quantum system to be in multiple states..."
      },
      "examples": [
        {
          "simple": "Imagine two coins that always land on opposite sides...",
          "detailed": "Consider a calcium atom that emits two photons..."
        }
      ],
      "commonMisconceptions": [
        {
          "misconception": "Entanglement allows faster-than-light communication",
          "correction": "Actually, no usable information can be transmitted..."
        }
      ]
    }
  ]
}
```

### Runtime Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TRANSCRIPT-DRIVEN SESSION FLOW                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚ Load Transcript â”‚                                               â”‚
â”‚  â”‚ + Glossary      â”‚                                               â”‚
â”‚  â”‚ + Examples      â”‚                                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚           â”‚                                                         â”‚
â”‚           â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ TTS: Speak      â”‚      â”‚ VAD: Monitor for interruption    â”‚    â”‚
â”‚  â”‚ Current Section â”‚â—„â”€â”€â”€â”€â–ºâ”‚ (running in parallel)            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚           â”‚                           â”‚                            â”‚
â”‚           â”‚                    User speaks                         â”‚
â”‚           â”‚                           â”‚                            â”‚
â”‚           â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚           â”‚              â”‚ Intent Classifier       â”‚              â”‚
â”‚           â”‚              â”‚ (On-Device, ~50ms)      â”‚              â”‚
â”‚           â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚           â”‚                           â”‚                            â”‚
â”‚           â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚           â”‚         â”‚                 â”‚                 â”‚         â”‚
â”‚           â”‚         â–¼                 â–¼                 â–¼         â”‚
â”‚           â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚           â”‚    â”‚ Simple  â”‚      â”‚ Medium  â”‚      â”‚ Complex â”‚     â”‚
â”‚           â”‚    â”‚ Intent  â”‚      â”‚ Intent  â”‚      â”‚ Intent  â”‚     â”‚
â”‚           â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â”‚
â”‚           â”‚         â”‚                â”‚                â”‚          â”‚
â”‚           â”‚         â–¼                â–¼                â–¼          â”‚
â”‚           â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚           â”‚    â”‚Handle   â”‚      â”‚Check    â”‚      â”‚Route to â”‚     â”‚
â”‚           â”‚    â”‚Locally  â”‚      â”‚Transcriptâ”‚     â”‚Frontier â”‚     â”‚
â”‚           â”‚    â”‚         â”‚      â”‚First    â”‚      â”‚LLM      â”‚     â”‚
â”‚           â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â”‚
â”‚           â”‚         â”‚                â”‚                â”‚          â”‚
â”‚           â”‚         â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚          â”‚
â”‚           â”‚         â”‚      â”‚                   â”‚     â”‚          â”‚
â”‚           â”‚         â”‚   In transcript?      Not found â”‚          â”‚
â”‚           â”‚         â”‚      â”‚                   â”‚     â”‚          â”‚
â”‚           â”‚         â”‚      â–¼                   â–¼     â”‚          â”‚
â”‚           â”‚         â”‚   Retrieve &        Route to   â”‚          â”‚
â”‚           â”‚         â”‚   Speak             Medium LLM â”‚          â”‚
â”‚           â”‚         â”‚                                â”‚          â”‚
â”‚           â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚           â”‚                    â”‚                                 â”‚
â”‚           â–¼                    â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Resume transcript from appropriate point                â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Intent Classification Categories

```swift
enum TutoringIntent: String, CaseIterable {
    // Category A: Pure navigation (no LLM)
    case continueListening      // "okay", "go on", "mmhmm"
    case repeatLast             // "can you repeat that?"
    case goBack                 // "go back to..."
    case skipAhead              // "skip this part"
    case adjustPace             // "slow down", "faster"
    case pause                  // "wait", "hold on"

    // Category B: Check transcript first
    case askDefinition          // "what does X mean?"
    case askForExample          // "can you give an example?"
    case askToRephrase          // "can you explain that differently?"
    case askForSummary          // "summarize what we covered"

    // Category C: Likely needs LLM
    case askQuestion            // "why does...", "how does..."
    case expressConfusion       // "I don't understand"
    case makeConnection         // "does this relate to..."
    case goOnTangent            // "what about...", off-topic

    // Category D: Definitely needs frontier LLM
    case challengeContent       // "I don't think that's right"
    case deepDive               // "tell me more about..."
    case hypothetical           // "what if..."
    case checkUnderstanding     // complex response to understanding check
}
```

### Routing Logic

```swift
func routeInteraction(
    intent: TutoringIntent,
    userUtterance: String,
    currentSection: TranscriptSection
) -> InteractionHandler {

    switch intent {
    // Category A: Handle immediately, no LLM
    case .continueListening:
        return .resumeTranscript

    case .repeatLast:
        return .replaySection(currentSection)

    case .goBack, .skipAhead:
        return .navigateTranscript(intent)

    case .adjustPace:
        return .adjustTTSRate(from: userUtterance)

    case .pause:
        return .pauseAndWait

    // Category B: Check transcript resources first
    case .askDefinition:
        let term = extractTerm(from: userUtterance)
        if let definition = currentSection.glossary[term] {
            return .speakFromTranscript(definition)
        } else {
            return .routeToMediumLLM(generateDefinition: term)
        }

    case .askForExample:
        if let example = currentSection.examples.first {
            return .speakFromTranscript(example.simple)
        } else {
            return .routeToMediumLLM(generateExample: currentSection.topic)
        }

    case .askToRephrase:
        // Try simpler explanation from transcript, or generate
        if let simpler = currentSection.simplerExplanation {
            return .speakFromTranscript(simpler)
        } else {
            return .routeToMediumLLM(rephrase: currentSection.content)
        }

    case .askForSummary:
        return .routeToMediumLLM(summarize: coveredSections)

    // Category C: Medium LLM likely sufficient
    case .askQuestion:
        // Check if answer is in transcript
        if let answer = searchTranscript(for: userUtterance) {
            return .speakFromTranscript(answer)
        }
        return .routeToMediumLLM(answer: userUtterance, context: currentSection)

    case .expressConfusion:
        return .routeToMediumLLM(clarify: currentSection.content)

    case .makeConnection:
        return .routeToMediumLLM(connect: userUtterance, to: currentSection)

    case .goOnTangent:
        // This needs real reasoning about relevance
        return .routeToFrontierLLM(tangent: userUtterance)

    // Category D: Frontier LLM required
    case .challengeContent:
        return .routeToFrontierLLM(
            evaluate: userUtterance,
            against: currentSection.content,
            withMisconceptions: currentSection.commonMisconceptions
        )

    case .deepDive:
        return .routeToFrontierLLM(expand: userUtterance, beyond: currentSection)

    case .hypothetical:
        return .routeToFrontierLLM(hypothetical: userUtterance)

    case .checkUnderstanding:
        return .routeToFrontierLLM(
            evaluateUnderstanding: userUtterance,
            expectedConcepts: currentSection.learningObjectives
        )
    }
}
```

---

## Feasibility Assessment

### âœ… Highly Feasible

1. **TTS-driven lecture delivery** - Already have Deepgram Aura-2, excellent quality
2. **Intent classification** - Small model, on-device, well-understood problem
3. **Transcript search** - Embeddings already implemented, just needs transcript indexing
4. **Simple response handling** - On-device 1B model can handle acknowledgments
5. **Navigation** - Pure logic, no AI needed

### âš ï¸ Needs Careful Design

1. **Intent classification accuracy** - Need to train/tune on tutoring-specific intents
2. **Transcript coverage** - Rich transcripts with glossaries/examples crucial
3. **Graceful escalation** - When to give up on transcript and go to LLM
4. **Context preservation** - When escalating to LLM, need to pass relevant context

### ğŸ¯ Key Success Factor: Transcript Quality

The better the transcript, the more stays in cheap tiers:

| Transcript Feature | Enables |
|-------------------|---------|
| Detailed glossary | Handle 80% of "what is X?" on-device |
| Multiple examples | Avoid generating examples |
| Common misconceptions | Catch errors without frontier LLM |
| Simpler rephrasing | Handle "explain differently" locally |
| Section summaries | Instant summaries without LLM |
| Related topics | Handle basic connections |

---

## Transcript Generation (Outside App)

User can generate transcripts using their own paid accounts:

### Prompt Template for Transcript Generation

```markdown
# Generate Educational Transcript

Create a detailed, structured transcript for a 45-minute voice-based
tutorial on [TOPIC].

## Requirements

1. **Format**: JSON following this schema:
   [Include JSON schema]

2. **Content Depth**: Graduate-level explanation suitable for someone
   with basic background in the field.

3. **Include for EACH section**:
   - Main lecture content (written for natural speech)
   - Speaking notes (pace, emphasis, pauses)
   - Glossary of technical terms used
   - 2-3 examples (simple and detailed versions)
   - Common misconceptions with corrections
   - Comprehension checkpoint questions

4. **Style**:
   - Conversational but precise
   - Build concepts progressively
   - Use analogies and real-world connections
   - Anticipate common questions

5. **Structure**:
   - Introduction (5 min)
   - 3-4 main sections (10 min each)
   - Synthesis/conclusion (5 min)

## Topic: [USER FILLS IN]

## Prerequisites assumed: [USER FILLS IN]

## Learning objectives: [USER FILLS IN]
```

### Import Flow

```
User generates transcript in Claude/ChatGPT (their own credits)
                    â”‚
                    â–¼
            JSON transcript file
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ UnaMentis Import    â”‚
         â”‚ - Validate schema    â”‚
         â”‚ - Index for search   â”‚
         â”‚ - Generate embeddingsâ”‚
         â”‚ - Store in Core Data â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         Ready for transcript-driven session
```

---

## Implementation Complexity

| Component | Complexity | Already Have? |
|-----------|------------|---------------|
| TTS playback with pacing | Low | âœ… TTS service exists |
| VAD interruption detection | Low | âœ… Silero VAD exists |
| Intent classifier | Medium | âŒ Need to add |
| Transcript parser/loader | Medium | âŒ Need to add |
| Transcript search (embeddings) | Low | âœ… Embedding service exists |
| Section navigation | Low | âŒ Need to add |
| Medium LLM routing | Medium | âš ï¸ Partially exists |
| Frontier LLM routing | Low | âœ… OpenAI/Anthropic exist |

**Estimated effort to add transcript-driven mode:** 2-3 weeks

---

## Summary: Is This Feasible?

### Yes, Highly Feasible

**Key insight confirmed:** The majority of a tutoring session CAN be handled by:
- TTS + transcript (40-50%)
- On-device intent + simple responses (25-35%)
- Transcript search + retrieval (15-20%)

**Only 10-20% truly needs frontier LLM capability.**

### Benefits

1. **Cost reduction:** 70%+ savings per session
2. **Latency reduction:** Most responses are instant (no LLM roundtrip)
3. **Offline capable:** Much of session works without network
4. **Quality control:** Pre-generated transcripts can be reviewed/edited
5. **Consistency:** Same high-quality explanation every time
6. **User agency:** Users can bring their own transcripts

### Trade-offs

1. **Transcript creation effort:** Need good transcripts upfront
2. **Less spontaneous:** Primarily follows prepared content
3. **Intent classifier accuracy:** Critical for good routing
4. **Edge cases:** Some interactions hard to classify

---

## Recommended Approach

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HYBRID MODEL: Transcript-First with AI Escalation                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  Default Mode: Transcript-Driven                                    â”‚
â”‚  â€¢ Read from high-quality prepared transcript                       â”‚
â”‚  â€¢ Handle simple interactions on-device                             â”‚
â”‚  â€¢ Search transcript for answers before calling LLM                 â”‚
â”‚  â€¢ Escalate to frontier LLM only when truly needed                  â”‚
â”‚                                                                      â”‚
â”‚  Fallback Mode: Full AI (when no transcript)                        â”‚
â”‚  â€¢ Original behavior - LLM handles everything                       â”‚
â”‚  â€¢ Higher cost, more flexible                                       â”‚
â”‚  â€¢ Good for exploration, tangents, unprepared topics                â”‚
â”‚                                                                      â”‚
â”‚  User chooses per-session based on their needs                      â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

*Analysis complete. This architecture is not only feasible but recommended.*
